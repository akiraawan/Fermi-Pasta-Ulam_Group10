{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Constants and settings\n",
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "a = 10  # Truncation of the real line for the loss calculation\n",
    "alpha = 0.1  # Alpha parameter from the equation\n",
    "\n",
    "# Define a custom layer for the characteristic transformation\n",
    "class CharacteristicLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CharacteristicLayer, self).__init__()\n",
    "        self.snn = self.add_weight(shape=(), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        t, x = inputs\n",
    "        return x - self.snn * t\n",
    "\n",
    "# Define the neural network architecture\n",
    "class FpuWaveNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FpuWaveNet, self).__init__()\n",
    "        self.characteristic_layer = CharacteristicLayer()\n",
    "        self.dense_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(50, activation='relu'),\n",
    "            tf.keras.layers.Dense(50, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z = self.characteristic_layer(inputs)\n",
    "        z = tf.expand_dims(z, -1)  # Ensure z has the right shape for Dense layers\n",
    "        return self.dense_layers(z)\n",
    "\n",
    "# Initialize models for U and V\n",
    "U_nn = FpuWaveNet()\n",
    "V_nn = FpuWaveNet()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Define the loss functions\n",
    "def loss_function(U_model, V_model, t_points, x_points):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(x_points)\n",
    "        U_outputs = U_model([t_points, x_points])\n",
    "        V_outputs = V_model([t_points, x_points])\n",
    "        U_x = tape.gradient(U_outputs, x_points)\n",
    "        U_xx = tape.gradient(U_x, x_points)\n",
    "        F_V = U_xx + alpha * tape.gradient(U_x * U_x, x_points)\n",
    "\n",
    "    # Loss for the PDE residuals and boundary conditions\n",
    "    loss_PDE = tf.reduce_mean(tf.square(V_outputs - F_V))\n",
    "    loss_boundary = tf.reduce_mean(tf.square(U_outputs)) + tf.reduce_mean(tf.square(V_outputs))\n",
    "\n",
    "    return loss_PDE + loss_boundary\n",
    "\n",
    "# Training loop\n",
    "def train(model_U, model_V, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            t_points = tf.random.uniform((100, 1), minval=-a, maxval=a)\n",
    "            x_points = tf.random.uniform((100, 1), minval=-a, maxval=a)\n",
    "            loss = loss_function(model_U, model_V, t_points, x_points)\n",
    "        gradients = tape.gradient(loss, model_U.trainable_variables + model_V.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model_U.trainable_variables + model_V.trainable_variables))\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "# Start training\n",
    "train(U_nn, V_nn, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Generate test data\n",
    "x_test = np.linspace(-a, a, 400)  # Spatial domain from -a to a\n",
    "t_test = np.zeros_like(x_test)    # You can vary time to see different time slices\n",
    "t_test = np.expand_dims(t_test, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# Predict using the trained models\n",
    "U_predictions = U_nn([t_test, x_test]).numpy().flatten()\n",
    "V_predictions = V_nn([t_test, x_test]).numpy().flatten()\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_test.flatten(), U_predictions, label='U(x)')\n",
    "plt.title('Profile of U')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('U(x)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_test.flatten(), V_predictions, label='V(x)')\n",
    "plt.title('Profile of V')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('V(x)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check residuals\n",
    "# def compute_residuals(U, V, x):\n",
    "#     with tf.GradientTape(persistent=True) as tape:\n",
    "#         tape.watch(x)\n",
    "#         U_x = tape.gradient(U, x)\n",
    "#         U_xx = tape.gradient(U_x, x)\n",
    "#         F_V = U_xx + alpha * tape.gradient(U_x * U_x, x)\n",
    "#     V_pred = V\n",
    "#     residual = tf.reduce_mean(tf.square(V_pred - F_V))\n",
    "#     return residual.numpy()\n",
    "\n",
    "# residuals = compute_residuals(tf.convert_to_tensor(U_predictions.reshape(-1, 1), dtype=tf.float32),\n",
    "#                               tf.convert_to_tensor(V_predictions.reshape(-1, 1), dtype=tf.float32),\n",
    "#                               tf.convert_to_tensor(x_test, dtype=tf.float32))\n",
    "\n",
    "# print(f\"Mean residual error: {residuals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import tensorflow as tf\n",
    "\n",
    "# Generate space and time points for prediction\n",
    "x_values = np.linspace(-a, a, 400)  # spatial domain\n",
    "time_values = np.linspace(0, 10, 100)  # time domain for the animation\n",
    "x_grid, t_grid = np.meshgrid(x_values, time_values)\n",
    "\n",
    "# Prepare data for prediction in correct shape\n",
    "x_grid_flat = x_grid.flatten()\n",
    "t_grid_flat = t_grid.flatten()\n",
    "test_input = [np.expand_dims(t_grid_flat, -1), np.expand_dims(x_grid_flat, -1)]\n",
    "\n",
    "# Predict using the trained model\n",
    "U_predictions = U_nn(test_input).numpy().reshape(t_grid.shape)\n",
    "\n",
    "# Create the animation\n",
    "fig, ax = plt.subplots()\n",
    "line, = ax.plot(x_values, U_predictions[0, :], color='b', lw=2)\n",
    "\n",
    "def update(frame):\n",
    "    line.set_ydata(U_predictions[frame, :])  # update the data\n",
    "    return line,\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(time_values), blit=True)\n",
    "ax.set_xlim([x_values.min(), x_values.max()])\n",
    "ax.set_ylim([U_predictions.min(), U_predictions.max()])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('U(x, t)')\n",
    "ax.set_title('Traveling Wave Solution Over Time')\n",
    "\n",
    "# Save the animation\n",
    "ani.save('traveling_wave.mp4', writer='ffmpeg', fps=15)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
