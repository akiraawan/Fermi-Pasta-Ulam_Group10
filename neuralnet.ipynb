{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96tchmxldpr5","outputId":"41e953ed-502f-4bbb-9796-bd0d1563e0dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Loss: [0.7492722]\n","Epoch 100, Loss: [0.02228179]\n","Epoch 200, Loss: [0.00220394]\n","Epoch 300, Loss: [0.00107712]\n","Epoch 400, Loss: [0.00020846]\n","Epoch 500, Loss: [0.0003935]\n","Epoch 600, Loss: [0.00153131]\n","Epoch 700, Loss: [0.00019624]\n","Epoch 800, Loss: [0.0009381]\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","class LearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, initial_learning_rate, decay_steps, decay_rate):\n","        self.initial_learning_rate = initial_learning_rate\n","        self.decay_steps = decay_steps\n","        self.decay_rate = decay_rate\n","\n","    def __call__(self, step):\n","        return self.initial_learning_rate * (self.decay_rate ** (step / self.decay_steps))\n","\n","class CharacteristicLayer(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super(CharacteristicLayer, self).__init__()\n","        self.snn = self.add_weight(shape=(), initializer=tf.random_uniform_initializer(minval=-1, maxval=1), trainable=True)\n","\n","    def call(self, inputs):\n","        t = inputs[..., 0]\n","        indices = inputs[..., 1]\n","        t = tf.cast(t, tf.float32)\n","        indices = tf.cast(indices, tf.float32)\n","        return indices - self.snn * t\n","\n","class FpuWaveNet(tf.keras.Model):\n","    def __init__(self):\n","        super(FpuWaveNet, self).__init__()\n","        self.characteristic_layer = CharacteristicLayer()\n","        self.q_layers = tf.keras.Sequential([\n","            tf.keras.layers.Dense(512, activation='tanh', kernel_initializer='lecun_normal'),\n","            tf.keras.layers.Dropout(0.2),\n","            tf.keras.layers.Dense(512, activation='tanh', kernel_initializer='lecun_normal'),\n","            tf.keras.layers.Dropout(0.2),\n","            tf.keras.layers.Dense(1)\n","        ])\n","        self.p_layers = tf.keras.Sequential([\n","            tf.keras.layers.Dense(512, activation='tanh', kernel_initializer='lecun_normal'),\n","            tf.keras.layers.Dropout(0.2),\n","            tf.keras.layers.Dense(512, activation='tanh', kernel_initializer='lecun_normal'),\n","            tf.keras.layers.Dropout(0.2),\n","            tf.keras.layers.Dense(1)\n","        ])\n","\n","    def call(self, inputs):\n","        z = self.characteristic_layer(inputs)\n","        z = tf.expand_dims(z, -1)\n","        q = self.q_layers(z)\n","        p = self.p_layers(z)\n","        return q, p\n","\n","def loss_function(model, t_points, indices, alpha):\n","    t_grid, idx_grid = tf.meshgrid(t_points, indices, indexing='ij')\n","    inputs = tf.stack([t_grid, idx_grid], axis=-1)\n","    q, p = model(inputs)\n","    N = indices.shape[0] // 2\n","\n","    q_m1 = tf.roll(q, shift=1, axis=1)  # q_{m-1}\n","    q_p1 = tf.roll(q, shift=-1, axis=1)  # q_{m+1}\n","    dp_dt = q_p1 + q_m1 - 2 * q + alpha * (tf.pow(q_p1 - q, 2) - tf.pow(q - q_m1, 2))\n","    dq_dt = p\n","\n","    # Calculate component loss functions\n","    residual_q = tf.reduce_mean(tf.square(dq_dt - p), axis=None)\n","    residual_p = tf.reduce_mean(tf.square(dp_dt - tf.roll(p, shift=-1, axis=1)), axis=None)\n","    Loss_GE = residual_q + residual_p\n","\n","    Loss_BC = (tf.square(q[0, -N + 1] - q[0, -N]) +\n","               tf.square(q[0, N] - q[0, N - 1]) +\n","               tf.square(p[0, -N + 1] - p[0, -N]) +\n","               tf.square(p[0, N] - p[0, N - 1]))\n","\n","    Loss_Limit = (tf.square(q[0, -N]) + tf.square(q[0, N]) +\n","                  tf.square(p[0, -N]) + tf.square(p[0, N]))\n","\n","    Loss_Trans = tf.square(q[0, 0])\n","\n","    return Loss_GE + Loss_BC + Loss_Limit + Loss_Trans\n","\n","def train(model, epochs, N, t_range, alpha):\n","    indices = tf.range(-N, N + 1, dtype=tf.float32)\n","\n","    # Seperate learning rates for network variables and wave speed\n","    lr_schedule_s = LearningRateSchedule(0.00001, 1000, 0.9)  # Decreased learning rate for wave speed\n","    lr_schedule_qp = LearningRateSchedule(0.00001, 1000, 0.9)  # Increased learning rate for network weights\n","    optimizer_s = tf.keras.optimizers.Adam(learning_rate=lr_schedule_s)\n","    optimizer_qp = tf.keras.optimizers.Adam(learning_rate=lr_schedule_qp)\n","\n","    # List to store losses for plotting\n","    loss_history = []\n","    speed_history = []\n","\n","    for epoch in range(epochs):\n","        # Randomly sample t_points within each epoch\n","        t_points = tf.random.uniform(shape=(500,), minval=t_range[0], maxval=t_range[1], dtype=tf.float32)\n","\n","        with tf.GradientTape() as tape:\n","            loss = loss_function(model, t_points, indices, alpha)\n","        gradients = tape.gradient(loss, model.trainable_variables)\n","\n","        # Apply gradient clipping\n","        gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n","\n","        # Apply different optimizers to different variables\n","        # Wave speed\n","        grad_s = [grad for grad, var in zip(gradients, model.trainable_variables) if 'characteristic_layer' in var.name]\n","        var_s = [var for var in model.trainable_variables if 'characteristic_layer' in var.name]\n","        optimizer_s.apply_gradients(zip(grad_s, var_s))\n","        # Network weights\n","        grad_qp = [grad for grad, var in zip(gradients, model.trainable_variables) if 'characteristic_layer' not in var.name]\n","        var_qp = [var for var in model.trainable_variables if 'characteristic_layer' not in var.name]\n","        optimizer_qp.apply_gradients(zip(grad_qp, var_qp))\n","\n","        # Record loss and predicted every 10 epochs (print every 100)\n","        if epoch % 10 == 0:\n","            loss_value = loss.numpy()\n","            loss_history.append(loss_value)\n","            speed_history.append(model.characteristic_layer.snn.numpy())\n","            if epoch % 100 == 0:\n","                print(f'Epoch {epoch}, Loss: {loss_value}')\n","\n","    return loss_history, speed_history\n","\n","# Model training\n","model = FpuWaveNet()\n","N = 32  # Number of particles on each side of the lattice\n","alpha = 0.1  # Non-linear coefficient\n","t_range = (-200, 200)  # Simulation time range\n","n_epochs = 1000\n","\n","loss_history, speed_history = train(model, n_epochs, N, t_range, alpha)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":6414,"status":"error","timestamp":1718139405790,"user":{"displayName":"Faris","userId":"15169451344397587918"},"user_tz":-60},"id":"BwZvtJqoj17g","outputId":"c5d6fab7-8fe7-4aa9-d2e8-51854f464588"},"outputs":[{"ename":"NameError","evalue":"name 'N' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-37c9f961d4b2>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Generate space and time points for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# particle indices, discretized model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtime_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_duration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Time domain for the animation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","import tensorflow as tf\n","\n","# Constants\n","a = 10  # Spatial domain endpoint\n","time_duration = 100  # Time for simulation in arbitrary units\n","time_steps = 100  # Number of time steps in the animation\n","\n","# Generate space and time points for prediction\n","indices = np.linspace(-N, N, 2 * N + 1)  # particle indices, discretized model\n","time_values = np.linspace(0, time_duration, time_steps)  # Time domain for the animation\n","\n","# Prepare input for predictions\n","test_inputs = np.array([[t, idx] for t in time_values for idx in indices])\n","\n","# Predict using the trained model\n","q_predictions, p_predictions = model(test_inputs.astype(np.float32))\n","q_predictions = q_predictions.numpy().reshape((time_steps, -1))  # Reshape q predictions\n","p_predictions = p_predictions.numpy().reshape((time_steps, -1))  # Reshape p predictions\n","\n","# Create the animation for 'q' using dots\n","fig, ax = plt.subplots()\n","line, = ax.plot(indices, q_predictions[0, :], 'o', color='b', label='q(t)', lw=2)  # Just dots\n","# line, = ax.plot(indices, q_predictions[0, :], '-o', color='b', label='q(t)', lw=2) # Interpolation\n","\n","def update(frame):\n","    # Update the data with dots\n","    line.set_ydata(q_predictions[frame, :])\n","    return line,\n","\n","ani = FuncAnimation(fig, update, frames=time_steps, blit=True)\n","ax.set_xlim([indices.min(), indices.max()])\n","ax.set_ylim([q_predictions.min() * 1.1, q_predictions.max() * 1.1])\n","ax.set_xlabel('Particle Index')\n","ax.set_ylabel('q(t)')\n","ax.set_title('Discrete Traveling Wave Solution Over Time')\n","\n","# Save the animation\n","ani.save('discrete_traveling_wave.mp4', writer='ffmpeg', fps=15)\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNSFiskMMbS3"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","import tensorflow as tf\n","\n","# Assuming model is defined and loaded correctly elsewhere\n","# Constants\n","a = 10  # Spatial domain endpoint\n","N = 10  # Number of particles\n","time_duration = 100  # Time for simulation in arbitrary units\n","time_steps = 100  # Number of time steps in the animation\n","\n","# Generate space and time points for prediction\n","indices = np.linspace(-N, N, 2 * N + 1)  # particle indices, discretized model\n","time_values = np.linspace(0, time_duration, time_steps)  # Time domain for the animation\n","\n","# Prepare input for predictions\n","test_inputs = np.array([[t, idx] for t in time_values for idx in indices])\n","\n","# Predict using the trained model\n","q_predictions, p_predictions = model(test_inputs.astype(np.float32))\n","q_predictions = q_predictions.numpy().reshape((time_steps, -1))  # Reshape q predictions\n","p_predictions = p_predictions.numpy().reshape((time_steps, -1))  # Reshape p predictions\n","\n","# Create the animation for 'q' with both lines and dots for better visualization\n","fig, ax = plt.subplots()\n","line, = ax.plot(indices, q_predictions[0, :], '-o', color='b', label='q(t)', lw=2)\n","\n","def update(frame):\n","    # Update the data, maintaining line and dots\n","    line.set_ydata(q_predictions[frame, :])\n","    return line,\n","\n","ani = FuncAnimation(fig, update, frames=time_steps, blit=True)\n","ax.set_xlim([indices.min(), indices.max()])\n","ax.set_ylim([q_predictions.min() * 1.1, q_predictions.max() * 1.1])\n","ax.set_xlabel('Particle Index')\n","ax.set_ylabel('q(t)')\n","ax.set_title('Discrete Traveling Wave Solution Over Time')\n","\n","# Save the animation\n","ani.save('discrete_traveling_wave_interpolated.mp4', writer='ffmpeg', fps=15)\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxKVXWP9N2FX"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","# Assuming model is defined and loaded correctly elsewhere\n","# Constants\n","a = 10  # Spatial domain endpoint\n","N = 10  # Number of particles\n","time_duration = 1000  # Time for simulation in arbitrary units\n","time_steps = 100  # Number of time steps for prediction\n","plot_times = [0, 9, 30, 20]  # Time points to plot\n","\n","# Generate space and time points for prediction\n","indices = np.linspace(-N, N, 2 * N + 1)  # particle indices, discretized model\n","time_values = np.linspace(0, time_duration, time_steps)  # Time domain for prediction\n","\n","# Prepare input for predictions\n","test_inputs = np.array([[t, idx] for t in time_values for idx in indices])\n","\n","# Predict using the trained model\n","q_predictions, p_predictions = model(test_inputs.astype(np.float32))\n","q_predictions = q_predictions.numpy().reshape((time_steps, -1))  # Reshape q predictions\n","p_predictions = p_predictions.numpy().reshape((time_steps, -1))  # Reshape p predictions\n","\n","# Plot the results at specified time points\n","fig, ax = plt.subplots()\n","colors = ['b', 'g', 'r', 'c', 'm']\n","labels = [f't={t}' for t in plot_times]\n","\n","for i, t in enumerate(plot_times):\n","    time_index = np.argmin(np.abs(time_values - t))  # Find the closest time index\n","    ax.plot(indices, q_predictions[time_index, :], '-o', color=colors[i], label=labels[i], lw=2)\n","\n","ax.set_xlim([indices.min(), indices.max()])\n","ax.set_ylim([q_predictions.min() * 1.1, q_predictions.max() * 1.1])\n","ax.set_xlabel('Particle Index')\n","ax.set_ylabel('q(t)')\n","ax.set_title('Discrete Traveling Wave Solution at Different Time Points')\n","ax.legend()\n","ax.grid(True)\n","\n","# Save the plot\n","plt.savefig('test')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r4wNTVIxeruE"},"outputs":[],"source":["snn_value = model.characteristic_layer.snn.numpy()\n","print(f'The trained value of snn is: {snn_value}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_PghkT8aiw5"},"outputs":[],"source":["plt.figure(figsize=(10, 6))\n","plt.plot(range(0, n_epochs, 10), speed_history, label='Speed Every 10 Epochs')\n","plt.xlabel('Epoch')\n","plt.ylabel('Wave Speed')\n","plt.title('Estimated Wave Speed Over Epochs')\n","plt.legend()\n","plt.grid(True)\n","plt.savefig('speed_plot.png')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqT4O8hbakcm"},"outputs":[],"source":["# Plotting the loss history after training\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 6))\n","plt.plot(range(0, n_epochs, 10), loss_history, label='Loss Every 10 Epochs')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.yscale('log')\n","plt.title('Training Loss Over Epochs')\n","plt.legend()\n","plt.grid(True)\n","plt.savefig('loss_plot.png')\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPS1YwX9Ua5IG4I30YdEaBX","provenance":[{"file_id":"1TP7ntbpJOui76YJ1OAW6zC6VPp8qLxu9","timestamp":1718139418088}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
